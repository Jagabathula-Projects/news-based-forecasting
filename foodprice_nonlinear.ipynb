{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow\n",
    "\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28174,
     "status": "ok",
     "timestamp": 1694798194105,
     "user": {
      "displayName": "Lakshminarayanan Subramanian",
      "userId": "05209319424673529095"
     },
     "user_tz": 240
    },
    "id": "av8A69_jjKv6",
    "outputId": "d4f61290-0604-4853-c957-958e5e7d4dc6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle as cp\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import datetime as dt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-hpirjye8Gl"
   },
   "outputs": [],
   "source": [
    "hidden_units = 200\n",
    "epochs = 100\n",
    "lookback = 7\n",
    "learning_rate = 0.001\n",
    "batch_size = 1024\n",
    "regularizer = 'l2'\n",
    "dropouts = {'dropout':0.55,'recurrent_dropout':0.3}\n",
    "\n",
    "crops = ['Onion','Potato','Wheat','Rice']\n",
    "crop = crops[0]\n",
    "\n",
    "others = True\n",
    "\n",
    "diff = False\n",
    "\n",
    "train_split = 2557 #- 1 #if using price diff\n",
    "seasons = [12,0]#,365]\n",
    "normalizations = [True]\n",
    "epochs = [100]\n",
    "hidden_units = [200]\n",
    "\n",
    "fileformat = 'food_price_data/%s.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPDTimeSeries(crop,start,end):\n",
    "    startdate = dt.datetime.strptime(start, '%Y-%m-%d').date()\n",
    "    enddate = dt.datetime.strptime(end, '%Y-%m-%d').date()\n",
    "    data = pd.read_csv(fileformat%(crop))\n",
    "    print(data.head())\n",
    "    price = data['price']\n",
    "    dates = data['date']\n",
    "    \n",
    "    dateindex = pd.DatetimeIndex(dates)\n",
    "    print(dateindex[0]+31)\n",
    "    print (dateindex)\n",
    "    price_data = pd.Series(price)#, index=dates)#index)\n",
    "    return price_data[start:end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSpanLag(data, events=[], look_back=7, look_ahead = 7, season=0):##span==1\n",
    "#     ### Adding span (required for weekly, monthly average data)\n",
    "#     if span>1:\n",
    "#         nts = []\n",
    "#         ind = 0\n",
    "#         while ind < len(ts):\n",
    "#             tmpts = ts[ind:ind+span]\n",
    "#             print (tmpts)\n",
    "#             dt = tmpts[0]\n",
    "#             vals = [k for k in tmpts]\n",
    "#             pr = sum(vals)/len(vals)\n",
    "#             nts.append((dt,pr))\n",
    "#             ind+=span\n",
    "#         ts = nts\n",
    "#     if not convert_to_Xy:\n",
    "#         return ts\n",
    "\n",
    "    ### Adding lag (based on look back and look ahead)\n",
    "    \n",
    "    if len(events) > 0:\n",
    "        input = np.append(data,events,axis=1)\n",
    "        if season>0:\n",
    "            if season==12:\n",
    "                season = np.array([k.date().month for k in pd.date_range(start='1/1/2006', end='12/31/2020')])\n",
    "            elif season==365:\n",
    "                season = np.array([k%season for k in range(data.shape[0])])\n",
    "                \n",
    "            season = season.reshape(len(season),1)\n",
    "            input = np.append(input,season,axis=1)\n",
    "        \n",
    "    else:\n",
    "        input = data\n",
    "        \n",
    "        \n",
    "    ind = 0\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    while ind + look_back + look_ahead < len(data):\n",
    "        \n",
    "        X = input[ind:ind+look_back]\n",
    "        Y = data[ind+look_back+look_ahead]\n",
    "        X_data.append(X)\n",
    "        y_data.append(Y)\n",
    "        ind+=1\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ren_train(X, y, hidden_units=100, learning_rate=0.01, epochs=200, batch_size=256,dropouts={'dropout':0.25,'recurrent_dropout':0.25},regularizer='l2'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', recurrent_regularizer='l2', activity_regularizer='l2', \n",
    "                   dropout=0.35, recurrent_dropout=0.25, \n",
    "                   input_shape=(X.shape[1], X.shape[-1])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    history = model.fit(X, y, epochs=100, verbose=1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "for epoch in epochs:\n",
    "    for hidden_unit in hidden_units:\n",
    "        for season in seasons:\n",
    "            for normalization in normalizations:\n",
    "                model_suffix = \"crop=%s_norm=%s_season=%s\"%(crop,normalization,season)\n",
    "                print(str(i),model_suffix)\n",
    "                i+=1\n",
    "                \n",
    "                food_price = pd.read_csv(fileformat%(crop))['price']\n",
    "                if diff:\n",
    "                    food_price = food_price.diff().dropna() \n",
    "                food_price = np.array(food_price).reshape(food_price.shape[0],1)\n",
    "\n",
    "                mean = np.mean(food_price)\n",
    "                std = np.std(food_price)\n",
    "                if normalization:\n",
    "                    mean = np.mean(food_price)\n",
    "                    std = np.std(food_price)\n",
    "                    food_price = (food_price - mean)/std\n",
    "\n",
    "                ### Events\n",
    "                events_train = np.load('embeddings/events_train.npy')\n",
    "                events_test = np.load('embeddings/events_test.npy')\n",
    "                events = np.append(events_train,events_test, axis=0)\n",
    "\n",
    "                ### Topics\n",
    "                topics_train = np.load('embeddings/toi.maxLDA_train.npy')\n",
    "                topic_test = np.load('embeddings/toi.maxLDA_test.npy')\n",
    "                topics = np.append(events_train,events_test, axis=0)\n",
    "\n",
    "                ### Word2Vec\n",
    "                w2v_train = np.load('embeddings/toi.W2V_train.npy')\n",
    "                w2v_test = np.load('embeddings/toi.W2V_test.npy')\n",
    "                w2v = np.append(events_train,events_test, axis=0)\n",
    "\n",
    "                X_event, y_event   = addSpanLag(food_price,events,look_back=7,look_ahead=6,season=season)\n",
    "                X_event_train = X_event[:train_split]\n",
    "                y_event_train = y_event[:train_split]\n",
    "                X_event_test = X_event[train_split:]\n",
    "                y_event_test = y_event[train_split:]\n",
    "\n",
    "                X_topics, y_topics   = addSpanLag(food_price,topics,look_back=7,look_ahead=6,season=season)\n",
    "                X_topics_train = X_topics[:train_split]\n",
    "                y_topics_train = y_topics[:train_split]\n",
    "                X_topics_test = X_topics[train_split:]\n",
    "                y_topics_test = y_topics[train_split:]\n",
    "\n",
    "                X_w2v, y_w2v   = addSpanLag(food_price,w2v,look_back=7,look_ahead=6,season=season)\n",
    "                X_w2v_train = X_w2v[:train_split]\n",
    "                y_w2v_train = y_w2v[:train_split]\n",
    "                X_w2v_test = X_w2v[train_split:]\n",
    "                y_w2v_test = y_w2v[train_split:]\n",
    "\n",
    "\n",
    "                X_noevent, y_noevent   = addSpanLag(food_price,look_back=7,look_ahead=6,season=season)\n",
    "                X_noevent_train = X_noevent[:train_split]\n",
    "                y_noevent_train = y_noevent[:train_split]\n",
    "                X_noevent_test = X_noevent[train_split:]\n",
    "                y_noevent_test = y_noevent[train_split:]\n",
    "\n",
    "\n",
    "                ### REN\n",
    "                model_event = ren_train(X_event_train,y_event_train)\n",
    "                \n",
    "                ### LSTM\n",
    "                model_noevent = ren_train(X_noevent_train,y_noevent_train)\n",
    "                \n",
    "\n",
    "                model_event.save('ren'+model_suffix)\n",
    "                model_noevent.save('lstm'+model_suffix)\n",
    "\n",
    "\n",
    "\n",
    "                if others:\n",
    "                    ### LDA\n",
    "                    model_topics = ren_train(X_topics_train,y_topics_train)\n",
    "\n",
    "                    ### LSTM\n",
    "                    model_w2v = ren_train(X_w2v_train,y_w2v_train)\n",
    "\n",
    "                    model_topics.save('lda'+model_suffix)\n",
    "                    model_w2v.save('w2v'+model_suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4Fh72a4Hm3abnJJgUwV9j",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
