{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQkvHmEpdWou"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle as cp\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import datetime as dt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FysU1WbCdZQi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLPBV47U9HIF"
   },
   "outputs": [],
   "source": [
    "def addSpanLag(data, events=[], look_back=7, look_ahead = 7, season=0):##span==1\n",
    "#     ### Adding span (required for weekly, monthly average data)\n",
    "#     if span>1:\n",
    "#         nts = []\n",
    "#         ind = 0\n",
    "#         while ind < len(ts):\n",
    "#             tmpts = ts[ind:ind+span]\n",
    "#             print (tmpts)\n",
    "#             dt = tmpts[0]\n",
    "#             vals = [k for k in tmpts]\n",
    "#             pr = sum(vals)/len(vals)\n",
    "#             nts.append((dt,pr))\n",
    "#             ind+=span\n",
    "#         ts = nts\n",
    "#     if not convert_to_Xy:\n",
    "#         return ts\n",
    "\n",
    "    ### Adding lag (based on look back and look ahead)\n",
    "\n",
    "    if len(events) > 0:\n",
    "        input = np.append(data,events,axis=1)\n",
    "    else:\n",
    "        input = data\n",
    "    if season>0:\n",
    "        season = np.array([k%season for k in range(data.shape[0])])\n",
    "        season = season.reshape(len(season),1)\n",
    "        input = np.append(input,season,axis=1)\n",
    "\n",
    "\n",
    "    ind = 0\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    while ind + look_back + look_ahead < len(data):\n",
    "\n",
    "        X = input[ind:ind+look_back]\n",
    "        Y = data[ind+look_back+look_ahead]\n",
    "        X_data.append(X)\n",
    "        y_data.append(Y)\n",
    "        ind+=1\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASgqUOrld8OX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZ2iWMzSd_gq"
   },
   "outputs": [],
   "source": [
    "def ren_train(X, y, hidden_units=100, learning_rate=0.01, epochs=60, batch_size=256,activation='relu',\\\n",
    "              dropout=0.0,recurrent_dropout=0.0,regularizer='l2',optimizer='adam',kernel_regularizer='l2'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, activation=activation,  kernel_regularizer='l2',#recurrent_regularizer='l2',\n",
    "                   dropout=dropout, recurrent_dropout=recurrent_dropout,unroll=True,\n",
    "                   input_shape=(X.shape[1], X.shape[-1])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse')#,metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    history = model.fit(X, y, epochs=epochs, verbose=1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvoUnEbQCSFh"
   },
   "outputs": [],
   "source": [
    "# wr = open(os.path.join(path,'Oct18','output.csv'),'w')\n",
    "# wr.write(\"crop,season,activation,drpt_recdrpt,optimizer,hidden_units,model,training_rmse,test_rmse,model,training_rmse,test_rmse,model,training_rmse,test_rmse,model,training_rmse,test_rmse,model,training_rmse,test_rmse\")\n",
    "# wr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUzyRHYIBGvA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fKO9An6U4N8"
   },
   "outputs": [],
   "source": [
    "\n",
    "crops = ['Onion','Potato','Wheat','Rice']\n",
    "crop = crops[0]\n",
    "\n",
    "\n",
    "train_split = 2557 - 1 #if using price diff\n",
    "seasons = [0,12]#,365]\n",
    "normalization = True\n",
    "\n",
    "path='/content/gdrive/MyDrive/Colab Notebooks/REN/'\n",
    "fileformat = path+'food_price_data/%s.csv'\n",
    "\n",
    "output_folder ='returnrate_onedayahead'\n",
    "\n",
    "### All together\n",
    "folders = ['all_models','models_norm_mse']\n",
    "dropouts = [0.0, 0.1, 0.2, 0.3]\n",
    "activations = ['tanh','relu']\n",
    "epochs=[60]\n",
    "optimizers = ['adam']#,'rmsprop']\n",
    "units = [5,10, 20, 50, 100]\n",
    "kernel_regularizers = ['l2']#,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LEQ5mKq29hoe",
    "outputId": "f198fad6-544d-45c2-b471-20b09e2b03d1"
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "normalization = False\n",
    "season = 0\n",
    "\n",
    "#for season in seasons:\n",
    "for activation in activations:\n",
    "  #for kernel_regularizer in kernel_regularizers:\n",
    "    #for optimizer in optimizers:\n",
    "      #for drpt in dropouts:\n",
    "        #for rec_drpt in dropouts:\n",
    "          for hidden_units in units:\n",
    "            for crop in crops:\n",
    "              epochs=70\n",
    "              model_suffix = \"crop=%s_season=%d_activation=%s_dropout=%.2f_optimizer=%s_units=%s_epochs=10_train=2010-15_kreg=%s\"\\\n",
    "              %(crop,season,activation,drpt,optimizer,hidden_units,kernel_regularizer)\n",
    "              print(str(i),model_suffix)\n",
    "              i+=1\n",
    "\n",
    "              food_price = pd.read_csv(fileformat%(crop))['price']\n",
    "              ### price diff\n",
    "              #food_price_diff = food_price.diff().dropna()\n",
    "              ### Return rate\n",
    "              food_price = np.log(food_price).diff()[1:]\n",
    "              price_diff = np.array(food_price).reshape(food_price.shape[0],1)\n",
    "\n",
    "              mean = np.mean(price_diff)\n",
    "              std = np.std(price_diff)\n",
    "              if normalization:\n",
    "                  price_diff = (price_diff - mean)/std\n",
    "\n",
    "              ### Events\n",
    "              events_train = np.load(os.path.join(path,'embeddings/events_train.npy'))\n",
    "              events_test = np.load(os.path.join(path,'embeddings/events_test.npy'))\n",
    "              events = np.append(events_train,events_test, axis=0)[1:]\n",
    "\n",
    "              ### Topics\n",
    "              topics_train = np.load(os.path.join(path,'embeddings/toi.maxLDA_train.npy'))\n",
    "              topic_test = np.load(os.path.join(path,'embeddings/toi.maxLDA_test.npy'))\n",
    "              topics = np.append(topics_train,topic_test, axis=0)[1:]\n",
    "\n",
    "              ### Word2Vec\n",
    "              w2v_train = np.load(os.path.join(path,'embeddings/toi.W2V_train.npy'))\n",
    "              w2v_test = np.load(os.path.join(path,'embeddings/toi.W2V_test.npy'))\n",
    "              w2v = np.append(w2v_train,w2v_test, axis=0)[1:]\n",
    "\n",
    "              ### Doc2Vec\n",
    "              d2v_train = np.load(os.path.join(path,'embeddings/toi.D2V_train.npy'))\n",
    "              d2v_test = np.load(os.path.join(path,'embeddings/toi.D2V_test.npy'))\n",
    "              d2v = np.append(d2v_train,d2v_test, axis=0)[1:]\n",
    "\n",
    "              X_event, y_event   = addSpanLag(price_diff,events,look_back=7,look_ahead=0,season=season)\n",
    "              X_event_train = X_event[train_split:]\n",
    "              y_event_train = y_event[train_split:]\n",
    "              X_event_test = X_event[train_split:]\n",
    "              y_event_test = y_event[train_split:]\n",
    "\n",
    "              X_topics, y_topics   = addSpanLag(price_diff,topics,look_back=7,look_ahead=0,season=season)\n",
    "              X_topics_train = X_topics[:train_split]\n",
    "              y_topics_train = y_topics[:train_split]\n",
    "              X_topics_test = X_topics[train_split:]\n",
    "              y_topics_test = y_topics[train_split:]\n",
    "\n",
    "              X_w2v, y_w2v   = addSpanLag(price_diff,w2v,look_back=7,look_ahead=0,season=season)\n",
    "              X_w2v_train = X_w2v[:train_split]\n",
    "              y_w2v_train = y_w2v[:train_split]\n",
    "              X_w2v_test = X_w2v[train_split:]\n",
    "              y_w2v_test = y_w2v[train_split:]\n",
    "\n",
    "              X_d2v, y_d2v   = addSpanLag(price_diff,d2v,look_back=7,look_ahead=0,season=season)\n",
    "              X_d2v_train = X_d2v[:train_split]\n",
    "              y_d2v_train = y_d2v[:train_split]\n",
    "              X_d2v_test = X_d2v[train_split:]\n",
    "              y_d2v_test = y_d2v[train_split:]\n",
    "\n",
    "\n",
    "              X_noevent, y_noevent   = addSpanLag(price_diff,look_back=7,look_ahead=0,season=season)\n",
    "              X_noevent_train = X_noevent[:train_split]\n",
    "              y_noevent_train = y_noevent[:train_split]\n",
    "              X_noevent_test = X_noevent[train_split:]\n",
    "              y_noevent_test = y_noevent[train_split:]\n",
    "\n",
    "\n",
    "              ### REN\n",
    "              model_event = ren_train(X_event_train,y_event_train,hidden_units=hidden_units, \\\n",
    "                                      activation=activation, dropout=drpt, optimizer=optimizer,epochs=epochs, kernel_regularizer=kernel_regularizer)\n",
    "              model_event.save(os.path.join(path,output_folder,'ren_'+model_suffix))\n",
    "              print(model_event.summary())\n",
    "              ### LSTM\n",
    "              model_noevent = ren_train(X_noevent_train,y_noevent_train,hidden_units=hidden_units, \\\n",
    "                                        activation=activation, dropout=drpt, optimizer=optimizer,epochs=epochs,kernel_regularizer=kernel_regularizer)\n",
    "              model_noevent.save(os.path.join(path,output_folder,'lstm_'+model_suffix))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              others=False\n",
    "\n",
    "              if others:\n",
    "                  ### LDA\n",
    "                  model_topics = ren_train(X_topics_train,y_topics_train,hidden_units=hidden_units, activation=activation, dropout=drpt, recurrent_dropout=rec_drpt,optimizer=optimizer)\n",
    "                  model_topics.save(os.path.join(path,output_folder,'lda_'+model_suffix))\n",
    "                  ### W2V\n",
    "                  model_w2v = ren_train(X_w2v_train,y_w2v_train,hidden_units=hidden_units, activation=activation, dropout=drpt, recurrent_dropout=rec_drpt,optimizer=optimizer)\n",
    "                  model_w2v.save(os.path.join(path,output_folder,'w2v_'+model_suffix))\n",
    "\n",
    "                  ### D2V\n",
    "                  model_d2v = ren_train(X_d2v_train,y_d2v_train,hidden_units=hidden_units, activation=activation, dropout=drpt, recurrent_dropout=rec_drpt,optimizer=optimizer)\n",
    "                  model_d2v.save(os.path.join(path,output_folder,'d2v_'+model_suffix))\n",
    "\n",
    "              e_res_tr = model_event.evaluate(X_event_train,y_event_train)\n",
    "              e_rmse_tr = np.sqrt(e_res_tr)\n",
    "              e_res = model_event.evaluate(X_event_test,y_event_test)\n",
    "              e_rmse = np.sqrt(e_res)\n",
    "              e_res_val = model_event.evaluate(X_event_test[:730],y_event_test[:730])\n",
    "              e_rmse_val = np.sqrt(e_res_val)\n",
    "\n",
    "              l_res_tr = model_noevent.evaluate(X_noevent_train,y_noevent_train)\n",
    "              l_rmse_tr = np.sqrt(l_res_tr)\n",
    "              l_res = model_noevent.evaluate(X_noevent_test,y_noevent_test)\n",
    "              l_rmse = np.sqrt(l_res)\n",
    "              l_res_val = model_noevent.evaluate(X_noevent_test[:730],y_noevent_test[:730])\n",
    "              l_rmse_val = np.sqrt(l_res_val)\n",
    "\n",
    "\n",
    "              if others:\n",
    "                t_res_tr = model_topics.evaluate(X_topics_train,y_topics_train)\n",
    "                t_rmse_tr = np.sqrt(t_res_tr)\n",
    "                t_res = model_topics.evaluate(X_topics_test,y_topics_test)\n",
    "                t_rmse = np.sqrt(t_res)\n",
    "\n",
    "                w_res_tr = model_w2v.evaluate(X_w2v_train,y_w2v_train)\n",
    "                w_rmse_tr = np.sqrt(w_res_tr)\n",
    "                w_res = model_w2v.evaluate(X_w2v_test,y_w2v_test)\n",
    "                w_rmse = np.sqrt(w_res)\n",
    "\n",
    "                d_res_tr = model_d2v.evaluate(X_d2v_train,y_d2v_train)\n",
    "                d_rmse_tr = (np.sqrt(d_res_tr) * std)\n",
    "                d_res = model_d2v.evaluate(X_d2v_test,y_d2v_test)\n",
    "                d_rmse = (np.sqrt(d_res) *std)\n",
    "\n",
    "              wr = open(os.path.join(path,output_folder,'output.csv'),'a')\n",
    "              wr.write(\"%s,%d,%d,%s,%s,%s,%.2f,%d,\\\n",
    "              events,%.3f,%.3f,%.3f,\\\n",
    "              lstm,%.3f,%.3f,%.3f,%s,2010-2015\\n\"\\\n",
    "              %(crop,season,epochs,activation,optimizer,kernel_regularizer,drpt,hidden_units,\n",
    "                 e_rmse_tr,e_rmse_val,e_rmse,\\\n",
    "                 l_rmse_tr,l_rmse_val,l_rmse,\\\n",
    "                kernel_regularizer))\n",
    "              wr.close()\n",
    "              print('file saved: %s,%d,%s,%.2f,%s,%d'%(crop,season+10,activation,drpt,optimizer,hidden_units))\n",
    "\n",
    "            # lda,%.3f,%.3f,\\\n",
    "              # w2v,%.3f,%.3f,\\\n",
    "              # d2v,%.3f,%.3f,\\\n",
    "              # t_rmse_tr,t_rmse,\\\n",
    "                #  w_rmse_tr,w_rmse,d_rmse_tr,d_rmse,\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCYluxFLYTwA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
